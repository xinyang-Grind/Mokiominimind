1.分词器 Tokennizer
    用分词器将单词映射到字典中的每页中

2.Pretrain数据
    低质量的预训练数据会导致模型胡言乱语
    因此尽量不采用大规模无监督的数据集做预训练
    尝试进行数据的清洗

    常用的中文数据集：
        匠数大模型SFT数据集
        Magpie-SFT数据集
        RLHF数据
        Reason数据集